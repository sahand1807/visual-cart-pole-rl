{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOI2G6W9a70rcbfhSr9tDo9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Notebook 2: Model Building and Training\n","\n","**Objective:** The goal of this notebook is to define a custom Convolutional Neural Network (CNN) using PyTorch and then use it to train a Reinforcement Learning agent with Stable Baselines3. The agent will learn to balance the pole in the custom visual environment.\n","\n","We will perform four main tasks:\n","1.  **Set up the environment** and redefine the custom `ImageWrapper`.\n","2.  **Define a custom CNN** feature extractor using PyTorch.\n","3.  **Configure a PPO agent** from Stable Baselines3 to use the network.\n","4.  **Run the training loop** and save the final, trained model."],"metadata":{"id":"wyhJpKaulo8f"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"Gbj-hUEWQx1P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759155715403,"user_tz":300,"elapsed":92773,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}},"outputId":"30289b6f-58ab-4f6b-8ff8-014c0c21c57e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Hit:2 https://cli.github.com/packages stable InRelease\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [81.0 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,014 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,805 kB]\n","Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,609 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,305 kB]\n","Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,577 kB]\n","Get:19 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,371 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,690 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n","Fetched 30.2 MB in 4s (7,653 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  swig4.0\n","Suggested packages:\n","  swig-doc swig-examples swig4.0-examples swig4.0-doc\n","The following NEW packages will be installed:\n","  swig swig4.0\n","0 upgraded, 2 newly installed, 0 to remove and 40 not upgraded.\n","Need to get 1,116 kB of archives.\n","After this operation, 5,542 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n","Fetched 1,116 kB in 1s (822 kB/s)\n","Selecting previously unselected package swig4.0.\n","(Reading database ... 126441 files and directories currently installed.)\n","Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n","Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n","Selecting previously unselected package swig.\n","Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n","Unpacking swig (4.0.2-1ubuntu1) ...\n","Setting up swig4.0 (4.0.2-1ubuntu1) ...\n","Setting up swig (4.0.2-1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","‚úÖ Setup complete. Environment is ready.\n"]}],"source":["# ==============================================================================\n","# SETUP AND INSTALLATIONS\n","# ==============================================================================\n","from google.colab import drive\n","import os\n","\n","# 1. Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# 2. Define Project Path and Create Symlink\n","PROJECT_PATH = '/content/drive/My Drive/PortfolioProjects/visual-cart-pole-rl'\n","\n","# Create a symlink for easy access\n","if not os.path.exists('/project'):\n","    !ln -sfn '{PROJECT_PATH}' /project\n","else:\n","    print(\"Symlink '/project' already exists.\")\n","\n","# 3. Install System Dependencies\n","!apt-get update && apt-get install -y swig\n","\n","# 4. Install Python Libraries\n","!pip install gymnasium[box2d] stable-baselines3[extra] opencv-python-headless -q\n","\n","print(\"‚úÖ Setup complete. Environment is ready.\")"]},{"cell_type":"markdown","source":["## Step 1: Imports and Environment Setup üìö\n","\n","First, we'll import all the necessary libraries for this notebook, including the custom `ImageWrapper` from the `utils/env_preprocessing.py` file we created. We can also add the project directory to the system path to ensure the import works reliably in Colab."],"metadata":{"id":"DLOQbGt3tAeT"}},{"cell_type":"code","source":["# ==============================================================================\n","# IMPORTS AND ENVIRONMENT SETUP\n","# ==============================================================================\n","import sys\n","import gymnasium as gym\n","import torch\n","import torch.nn as nn\n","from stable_baselines3 import PPO\n","from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n","from stable_baselines3.common.env_util import make_vec_env\n","from stable_baselines3.common.vec_env import VecTransposeImage\n","\n","# Add the project directory to the system path to ensure imports work\n","if '/project' not in sys.path:\n","    sys.path.append('/project')\n","\n","# Import our custom classes\n","from utils.env_preprocessing import ImageWrapper\n","\n","print(\"Imports complete and custom wrapper is ready to be used.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YksoozNKn0MS","executionInfo":{"status":"ok","timestamp":1759155728825,"user_tz":300,"elapsed":13419,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}},"outputId":"b11c5390-8666-4a62-d5a0-ae260fcc0fd1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n","Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n","See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n","/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]},{"output_type":"stream","name":"stdout","text":["Imports complete and custom wrapper is ready to be used.\n"]}]},{"cell_type":"markdown","source":["## Step 2: Define a Custom CNN Feature Extractor üß†\n","\n","Stable Baselines3's `CnnPolicy` is powerful, but to get deeper and attain more control, we will desing our feature extractor here! We will build a custom CNN using PyTorch that inherits from `BaseFeaturesExtractor`.\n","\n","Our network will consist of three convolutional layers followed by a fully connected layer. This replicates a standard architecture for processing images in reinforcement learning, designed to effectively downsample the image and extract key spatial features."],"metadata":{"id":"ea1qUUGQt9xG"}},{"cell_type":"code","source":["# ==============================================================================\n","# CUSTOM CNN CLASS DEFINITION\n","# ==============================================================================\n","class CustomCNN(BaseFeaturesExtractor):\n","    \"\"\"\n","    A custom CNN feature extractor with configurable channel dimensions.\n","\n","    :param observation_space: The observation space of the environment.\n","    :param features_dim: The number of features to extract.\n","    :param c1_out: Number of output channels for the first convolutional layer.\n","    :param c2_out: Number of output channels for the second convolutional layer.\n","    :param c3_out: Number of output channels for the third convolutional layer.\n","    \"\"\"\n","    def __init__(\n","        self,\n","        observation_space: gym.spaces.Box,\n","        features_dim: int = 128,\n","        c1_out: int = 32,\n","        c2_out: int = 64,\n","        c3_out: int = 64\n","    ):\n","        super().__init__(observation_space, features_dim)\n","        n_input_channels = observation_space.shape[0]\n","\n","        # Define the CNN layers using the configurable parameters\n","        self.cnn = nn.Sequential(\n","            nn.Conv2d(n_input_channels, c1_out, kernel_size=8, stride=4, padding=0),\n","            nn.ReLU(),\n","            nn.Conv2d(c1_out, c2_out, kernel_size=4, stride=2, padding=0),\n","            nn.ReLU(),\n","            nn.Conv2d(c2_out, c3_out, kernel_size=3, stride=1, padding=0),\n","            nn.ReLU(),\n","            nn.Flatten(),\n","        )\n","\n","        # Compute the flattened feature size after the CNN layers\n","        with torch.no_grad():\n","            sample_tensor = torch.as_tensor(observation_space.sample()[None]).float()\n","            n_flatten = self.cnn(sample_tensor).shape[1]\n","\n","        # Define the final linear layers\n","        self.linear = nn.Sequential(\n","            nn.Linear(n_flatten, features_dim),\n","            nn.ReLU()\n","        )\n","\n","    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n","        return self.linear(self.cnn(observations))\n"],"metadata":{"id":"oSM7X6fktZdi","executionInfo":{"status":"ok","timestamp":1759155728830,"user_tz":300,"elapsed":2,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["### Step 2.1: Test the Custom CNN üß™\n","\n","Before using our `CustomCNN` in the full training pipeline, we can do a quick sanity check. We will:\n","1.  Create a temporary, dummy environment to get the correct observation space shape.\n","2.  Instantiate our `CustomCNN` model.\n","3.  Create a random dummy observation (input tensor).\n","4.  Perform a single forward pass and check the shape of the output tensor.\n","\n","This ensures that our network's layers are connected correctly and produce an output with the expected dimensions (`batch_size`, `features_dim`).\n","\n","---\n","\n","Note:\n","\n","1. `make_vec_env`: The Training Accelerator\n","    - A helper function from Stable Baselines3 that creates multiple, parallel copies of an environment.\n","    -  Instead of training on a single instance of the CartPole env, `make_vec_env` sets up several envs to run simultaneously. When we call the step() function, it sends an action to each environment and collects the results (the next image, the reward, etc.) from all of them at once.\n","\n","2. `VecTransposeImage`: The Data Shaper\n","    - A wrapper that changes the order of an image's dimensions.\n","    - Our environment (using OpenCV and Gymnasium) produces images in channels-last format: (Height, Width, Channels). PyTorch's CNNs require images in channels-first format: (Channels, Height, Width).\n"],"metadata":{"id":"JIYm0LdIwQqN"}},{"cell_type":"code","source":["# ==============================================================================\n","# TEST THE CUSTOM CNN\n","# ==============================================================================\n","print(\"--- Testing CustomCNN ---\")\n","\n","# 1. Create a dummy environment to get the observation space\n","# We follow the same wrapping steps as we will for the real training\n","test_env = make_vec_env('CartPole-v1', n_envs=4, env_kwargs={'render_mode': 'rgb_array'}, wrapper_class=ImageWrapper)\n","test_env = VecTransposeImage(test_env)\n","obs_space = test_env.observation_space\n","print(f\"Observation space shape: {obs_space.shape}\") # Should be (1, 84, 84)\n","\n","# 2. Instantiate the CustomCNN\n","# We use the observation space from our wrapped environment\n","cnn_test_model = CustomCNN(observation_space=obs_space, features_dim=128)\n","print(f\"CNN Model Initialized:\\n{cnn_test_model}\")\n","\n","# 3. Create a dummy observation\n","# .reset() gives us a sample observation from the environment\n","dummy_obs = test_env.reset()\n","input_tensor = torch.as_tensor(dummy_obs).float()\n","print(f\"\\nInput tensor shape: {input_tensor.shape}\") # Should be (n_envs, 1, 84, 84)\n","\n","# 4. Perform a forward pass\n","features = cnn_test_model(input_tensor)\n","print(f\"Output features shape: {features.shape}\") # Should be (n_envs, features_dim)\n","\n","# 5. Verify the output shape\n","n_envs = test_env.num_envs\n","expected_shape = (n_envs, cnn_test_model.features_dim)\n","assert features.shape == expected_shape, f\"Shape mismatch! Expected {expected_shape}, got {features.shape}\"\n","\n","print(\"\\n‚úÖ Test passed! The CustomCNN is working as expected.\")\n","\n","# Clean up the test environment\n","test_env.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"62TNgaTKwcf0","executionInfo":{"status":"ok","timestamp":1759155729973,"user_tz":300,"elapsed":1142,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}},"outputId":"b07dd314-99fa-4013-ee01-31e5061a4ac6"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Testing CustomCNN ---\n","Observation space shape: (1, 84, 84)\n","CNN Model Initialized:\n","CustomCNN(\n","  (cnn): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(8, 8), stride=(4, 4))\n","    (1): ReLU()\n","    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n","    (5): ReLU()\n","    (6): Flatten(start_dim=1, end_dim=-1)\n","  )\n","  (linear): Sequential(\n","    (0): Linear(in_features=3136, out_features=128, bias=True)\n","    (1): ReLU()\n","  )\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/pygame/pkgdata.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n","  from pkg_resources import resource_stream, resource_exists\n","/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n","/usr/local/lib/python3.12/dist-packages/pkg_resources/__init__.py:3154: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n","Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n","  declare_namespace(pkg)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Input tensor shape: torch.Size([4, 1, 84, 84])\n","Output features shape: torch.Size([4, 128])\n","\n","‚úÖ Test passed! The CustomCNN is working as expected.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n","  return datetime.utcnow().replace(tzinfo=utc)\n"]}]},{"cell_type":"markdown","source":["## Step 3: Configure and Train the PPO Agent üöÄ\n","\n","This is the final step in the training process. We will now define our learning agent, connect it to our custom environment and neural network, and start the training process.\n","\n","Here's a detailed breakdown of the components involved:\n","\n","* **The Agent (PPO):** We are using **Proximal Policy Optimization (PPO)**, a state-of-the-art reinforcement learning algorithm. PPO is known for its stability and strong performance. Its core job is to analyze the agent's experiences (the images, actions, and rewards) and update the neural network to produce better actions over time. It intelligently balances **exploration** (trying new things to find better strategies) and **exploitation** (using the best-known strategies).\n","\n","* **The Policy (`CnnPolicy`):** This is a pre-built policy structure from Stable Baselines3 that is specifically designed for tasks with image-based observations. It provides the general architecture, which includes a feature extractor (the CNN part) and \"heads\" that decide on the next action and estimate the value of the current state.\n","\n","* **The Custom Feature Extractor (`CustomCNN`):** This is our key customization. We are telling the `CnnPolicy` to *not* use its default CNN. Instead, we instruct it to use our `CustomCNN` class as its feature extractor. We pass this instruction using the `policy_kwargs` dictionary, which allows us to configure the policy's internal components.\n","\n","* **The Training Process (`model.learn()`):** When we call this function, the main training loop begins. The agent will repeatedly perform actions in our four parallel environments, collect batches of experience, and use the PPO algorithm to update its network weights. We will see its performance gradually improve from random guessing to intentional, stable control."],"metadata":{"id":"C00thPoHzxi_"}},{"cell_type":"code","source":["# Check if a CUDA-enabled GPU is available\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"‚úÖ GPU is available and will be used: {torch.cuda.get_device_name(0)}\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"‚ö†Ô∏è GPU not found, using CPU.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"78_8o4Iy2C4E","executionInfo":{"status":"ok","timestamp":1759155743413,"user_tz":300,"elapsed":37,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}},"outputId":"c7895531-8a7f-40e7-cdec-f7681aa51092"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ GPU is available and will be used: Tesla T4\n"]}]},{"cell_type":"code","source":["# ==============================================================================\n","# TRAINING THE AGENT\n","# ==============================================================================\n","# --- Configure the Policy ---\n","# The policy_kwargs dictionary is our way of telling the PPO agent's CnnPolicy\n","# to use our custom CNN class and its specific parameters.\n","policy_kwargs = dict(\n","    features_extractor_class=CustomCNN,\n","    features_extractor_kwargs=dict(\n","        features_dim=128,\n","        c1_out=32,\n","        c2_out=64,\n","        c3_out=64\n","    ),\n",")\n","\n","# --- Create the Final Vectorized Environment ---\n","# We use our previously tested setup with 4 parallel environments.\n","vec_env = make_vec_env(\n","    'CartPole-v1',\n","    n_envs=4,\n","    env_kwargs={'render_mode': 'rgb_array'},\n","    wrapper_class=ImageWrapper\n",")\n","vec_env = VecTransposeImage(vec_env)\n","\n","# --- Define the PPO Model ---\n","# We instantiate the PPO agent with our policy, environment, and custom arguments.\n","# `verbose=1` will print the training progress.\n","model = PPO(\n","    \"CnnPolicy\",\n","    vec_env,\n","    policy_kwargs=policy_kwargs,\n","    verbose=1,\n","    tensorboard_log=\"/project/logs/ppo_visual_cartpole_tensorboard/\"\n",")\n","\n","# --- Start Training ---\n","# The agent will train for 250,000 total steps. A \"step\" is a single\n","# action taken in one of the parallel environments.\n","model.learn(total_timesteps=250000)\n","\n","# --- Save the Trained Model ---\n","# After training, the model's learned weights are saved to a file. This file\n","# contains the complete agent, ready for evaluation in the next notebook.\n","model.save(\"/project/models/ppo_visual_cartpole\")\n","\n","print(\"\\n‚úÖ Training complete and model saved to /project/models/ppo_visual_cartpole.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYfSK48L0tW3","executionInfo":{"status":"ok","timestamp":1759157310225,"user_tz":300,"elapsed":1142657,"user":{"displayName":"Sahand Sadeghi","userId":"05311083868666213793"}},"outputId":"b19ae555-d0e4-433b-d5cc-8219773a70b9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n","Logging to /project/logs/ppo_visual_cartpole_tensorboard/PPO_2\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 21.6     |\n","|    ep_rew_mean     | 21.6     |\n","| time/              |          |\n","|    fps             | 285      |\n","|    iterations      | 1        |\n","|    time_elapsed    | 28       |\n","|    total_timesteps | 8192     |\n","---------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 22.1         |\n","|    ep_rew_mean          | 22.1         |\n","| time/                   |              |\n","|    fps                  | 246          |\n","|    iterations           | 2            |\n","|    time_elapsed         | 66           |\n","|    total_timesteps      | 16384        |\n","| train/                  |              |\n","|    approx_kl            | 0.0047462834 |\n","|    clip_fraction        | 0.011        |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.69        |\n","|    explained_variance   | -0.00395     |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 3.74         |\n","|    n_updates            | 10           |\n","|    policy_gradient_loss | -0.000747    |\n","|    value_loss           | 13.1         |\n","------------------------------------------\n","------------------------------------------\n","| rollout/                |              |\n","|    ep_len_mean          | 27.4         |\n","|    ep_rew_mean          | 27.4         |\n","| time/                   |              |\n","|    fps                  | 238          |\n","|    iterations           | 3            |\n","|    time_elapsed         | 102          |\n","|    total_timesteps      | 24576        |\n","| train/                  |              |\n","|    approx_kl            | 0.0122494735 |\n","|    clip_fraction        | 0.0917       |\n","|    clip_range           | 0.2          |\n","|    entropy_loss         | -0.684       |\n","|    explained_variance   | 0.375        |\n","|    learning_rate        | 0.0003       |\n","|    loss                 | 10.4         |\n","|    n_updates            | 20           |\n","|    policy_gradient_loss | -0.0128      |\n","|    value_loss           | 22.2         |\n","------------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 33          |\n","|    ep_rew_mean          | 33          |\n","| time/                   |             |\n","|    fps                  | 233         |\n","|    iterations           | 4           |\n","|    time_elapsed         | 140         |\n","|    total_timesteps      | 32768       |\n","| train/                  |             |\n","|    approx_kl            | 0.013544437 |\n","|    clip_fraction        | 0.182       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.654      |\n","|    explained_variance   | 0.332       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 14.8        |\n","|    n_updates            | 30          |\n","|    policy_gradient_loss | -0.0161     |\n","|    value_loss           | 35          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 43.3        |\n","|    ep_rew_mean          | 43.3        |\n","| time/                   |             |\n","|    fps                  | 230         |\n","|    iterations           | 5           |\n","|    time_elapsed         | 177         |\n","|    total_timesteps      | 40960       |\n","| train/                  |             |\n","|    approx_kl            | 0.015353845 |\n","|    clip_fraction        | 0.187       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.614      |\n","|    explained_variance   | 0.331       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 18.2        |\n","|    n_updates            | 40          |\n","|    policy_gradient_loss | -0.014      |\n","|    value_loss           | 42.5        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 42.9       |\n","|    ep_rew_mean          | 42.9       |\n","| time/                   |            |\n","|    fps                  | 229        |\n","|    iterations           | 6          |\n","|    time_elapsed         | 214        |\n","|    total_timesteps      | 49152      |\n","| train/                  |            |\n","|    approx_kl            | 0.01149849 |\n","|    clip_fraction        | 0.14       |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.587     |\n","|    explained_variance   | 0.304      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 27.3       |\n","|    n_updates            | 50         |\n","|    policy_gradient_loss | -0.00736   |\n","|    value_loss           | 49.3       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 41.3        |\n","|    ep_rew_mean          | 41.3        |\n","| time/                   |             |\n","|    fps                  | 228         |\n","|    iterations           | 7           |\n","|    time_elapsed         | 251         |\n","|    total_timesteps      | 57344       |\n","| train/                  |             |\n","|    approx_kl            | 0.011269663 |\n","|    clip_fraction        | 0.143       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.554      |\n","|    explained_variance   | 0.335       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 35          |\n","|    n_updates            | 60          |\n","|    policy_gradient_loss | -0.0062     |\n","|    value_loss           | 55.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 42.2        |\n","|    ep_rew_mean          | 42.2        |\n","| time/                   |             |\n","|    fps                  | 227         |\n","|    iterations           | 8           |\n","|    time_elapsed         | 287         |\n","|    total_timesteps      | 65536       |\n","| train/                  |             |\n","|    approx_kl            | 0.011175357 |\n","|    clip_fraction        | 0.127       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.53       |\n","|    explained_variance   | 0.362       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 34.5        |\n","|    n_updates            | 70          |\n","|    policy_gradient_loss | -0.00238    |\n","|    value_loss           | 61.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 43.9        |\n","|    ep_rew_mean          | 43.9        |\n","| time/                   |             |\n","|    fps                  | 226         |\n","|    iterations           | 9           |\n","|    time_elapsed         | 325         |\n","|    total_timesteps      | 73728       |\n","| train/                  |             |\n","|    approx_kl            | 0.012691328 |\n","|    clip_fraction        | 0.146       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.507      |\n","|    explained_variance   | 0.378       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 25.1        |\n","|    n_updates            | 80          |\n","|    policy_gradient_loss | -0.00406    |\n","|    value_loss           | 59.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 46.2        |\n","|    ep_rew_mean          | 46.2        |\n","| time/                   |             |\n","|    fps                  | 226         |\n","|    iterations           | 10          |\n","|    time_elapsed         | 362         |\n","|    total_timesteps      | 81920       |\n","| train/                  |             |\n","|    approx_kl            | 0.010261558 |\n","|    clip_fraction        | 0.127       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.49       |\n","|    explained_variance   | 0.386       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 28.5        |\n","|    n_updates            | 90          |\n","|    policy_gradient_loss | -0.000595   |\n","|    value_loss           | 61          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 44.5        |\n","|    ep_rew_mean          | 44.5        |\n","| time/                   |             |\n","|    fps                  | 225         |\n","|    iterations           | 11          |\n","|    time_elapsed         | 399         |\n","|    total_timesteps      | 90112       |\n","| train/                  |             |\n","|    approx_kl            | 0.012487402 |\n","|    clip_fraction        | 0.14        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.486      |\n","|    explained_variance   | 0.383       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 31.5        |\n","|    n_updates            | 100         |\n","|    policy_gradient_loss | -0.00237    |\n","|    value_loss           | 63.7        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 47.4       |\n","|    ep_rew_mean          | 47.4       |\n","| time/                   |            |\n","|    fps                  | 225        |\n","|    iterations           | 12         |\n","|    time_elapsed         | 436        |\n","|    total_timesteps      | 98304      |\n","| train/                  |            |\n","|    approx_kl            | 0.01636137 |\n","|    clip_fraction        | 0.156      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.472     |\n","|    explained_variance   | 0.282      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 39.9       |\n","|    n_updates            | 110        |\n","|    policy_gradient_loss | -0.00376   |\n","|    value_loss           | 73.3       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 46.7        |\n","|    ep_rew_mean          | 46.7        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 13          |\n","|    time_elapsed         | 473         |\n","|    total_timesteps      | 106496      |\n","| train/                  |             |\n","|    approx_kl            | 0.010684527 |\n","|    clip_fraction        | 0.114       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.457      |\n","|    explained_variance   | 0.297       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 40.6        |\n","|    n_updates            | 120         |\n","|    policy_gradient_loss | -0.0021     |\n","|    value_loss           | 74.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 46.8        |\n","|    ep_rew_mean          | 46.8        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 14          |\n","|    time_elapsed         | 510         |\n","|    total_timesteps      | 114688      |\n","| train/                  |             |\n","|    approx_kl            | 0.011518282 |\n","|    clip_fraction        | 0.123       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.453      |\n","|    explained_variance   | 0.344       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 40.1        |\n","|    n_updates            | 130         |\n","|    policy_gradient_loss | -0.00065    |\n","|    value_loss           | 74.7        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 48.3       |\n","|    ep_rew_mean          | 48.3       |\n","| time/                   |            |\n","|    fps                  | 224        |\n","|    iterations           | 15         |\n","|    time_elapsed         | 547        |\n","|    total_timesteps      | 122880     |\n","| train/                  |            |\n","|    approx_kl            | 0.01164717 |\n","|    clip_fraction        | 0.103      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.445     |\n","|    explained_variance   | 0.374      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 31.2       |\n","|    n_updates            | 140        |\n","|    policy_gradient_loss | -0.00181   |\n","|    value_loss           | 69.4       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 51.5        |\n","|    ep_rew_mean          | 51.5        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 16          |\n","|    time_elapsed         | 583         |\n","|    total_timesteps      | 131072      |\n","| train/                  |             |\n","|    approx_kl            | 0.010607496 |\n","|    clip_fraction        | 0.121       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.437      |\n","|    explained_variance   | 0.371       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 30.1        |\n","|    n_updates            | 150         |\n","|    policy_gradient_loss | -0.000365   |\n","|    value_loss           | 67.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 52.2        |\n","|    ep_rew_mean          | 52.2        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 17          |\n","|    time_elapsed         | 620         |\n","|    total_timesteps      | 139264      |\n","| train/                  |             |\n","|    approx_kl            | 0.012166936 |\n","|    clip_fraction        | 0.133       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.426      |\n","|    explained_variance   | 0.348       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 30          |\n","|    n_updates            | 160         |\n","|    policy_gradient_loss | -0.000442   |\n","|    value_loss           | 64.7        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 47.9       |\n","|    ep_rew_mean          | 47.9       |\n","| time/                   |            |\n","|    fps                  | 224        |\n","|    iterations           | 18         |\n","|    time_elapsed         | 657        |\n","|    total_timesteps      | 147456     |\n","| train/                  |            |\n","|    approx_kl            | 0.01167354 |\n","|    clip_fraction        | 0.108      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.429     |\n","|    explained_variance   | 0.365      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 33.9       |\n","|    n_updates            | 170        |\n","|    policy_gradient_loss | -0.000979  |\n","|    value_loss           | 62.1       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 47          |\n","|    ep_rew_mean          | 47          |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 19          |\n","|    time_elapsed         | 694         |\n","|    total_timesteps      | 155648      |\n","| train/                  |             |\n","|    approx_kl            | 0.012889904 |\n","|    clip_fraction        | 0.112       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.407      |\n","|    explained_variance   | 0.343       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 40.5        |\n","|    n_updates            | 180         |\n","|    policy_gradient_loss | -0.000606   |\n","|    value_loss           | 68.9        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 49.9        |\n","|    ep_rew_mean          | 49.9        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 20          |\n","|    time_elapsed         | 731         |\n","|    total_timesteps      | 163840      |\n","| train/                  |             |\n","|    approx_kl            | 0.015145515 |\n","|    clip_fraction        | 0.126       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.424      |\n","|    explained_variance   | 0.316       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 39.5        |\n","|    n_updates            | 190         |\n","|    policy_gradient_loss | -0.000728   |\n","|    value_loss           | 71.5        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 44          |\n","|    ep_rew_mean          | 44          |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 21          |\n","|    time_elapsed         | 767         |\n","|    total_timesteps      | 172032      |\n","| train/                  |             |\n","|    approx_kl            | 0.013904769 |\n","|    clip_fraction        | 0.123       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.439      |\n","|    explained_variance   | 0.318       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 27.3        |\n","|    n_updates            | 200         |\n","|    policy_gradient_loss | -0.00275    |\n","|    value_loss           | 71.3        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 47          |\n","|    ep_rew_mean          | 47          |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 22          |\n","|    time_elapsed         | 804         |\n","|    total_timesteps      | 180224      |\n","| train/                  |             |\n","|    approx_kl            | 0.012725174 |\n","|    clip_fraction        | 0.117       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.427      |\n","|    explained_variance   | 0.309       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 39.1        |\n","|    n_updates            | 210         |\n","|    policy_gradient_loss | 0.000743    |\n","|    value_loss           | 76.6        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 50.5        |\n","|    ep_rew_mean          | 50.5        |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 23          |\n","|    time_elapsed         | 841         |\n","|    total_timesteps      | 188416      |\n","| train/                  |             |\n","|    approx_kl            | 0.016655782 |\n","|    clip_fraction        | 0.133       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.437      |\n","|    explained_variance   | 0.327       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 37          |\n","|    n_updates            | 220         |\n","|    policy_gradient_loss | -0.00414    |\n","|    value_loss           | 70.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 44.8        |\n","|    ep_rew_mean          | 44.8        |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 24          |\n","|    time_elapsed         | 878         |\n","|    total_timesteps      | 196608      |\n","| train/                  |             |\n","|    approx_kl            | 0.012988531 |\n","|    clip_fraction        | 0.128       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.439      |\n","|    explained_variance   | 0.32        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 33.3        |\n","|    n_updates            | 230         |\n","|    policy_gradient_loss | -0.0011     |\n","|    value_loss           | 72.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 49.2        |\n","|    ep_rew_mean          | 49.2        |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 25          |\n","|    time_elapsed         | 914         |\n","|    total_timesteps      | 204800      |\n","| train/                  |             |\n","|    approx_kl            | 0.013888593 |\n","|    clip_fraction        | 0.128       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.445      |\n","|    explained_variance   | 0.322       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 31.9        |\n","|    n_updates            | 240         |\n","|    policy_gradient_loss | -0.00126    |\n","|    value_loss           | 73.2        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 49          |\n","|    ep_rew_mean          | 49          |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 26          |\n","|    time_elapsed         | 950         |\n","|    total_timesteps      | 212992      |\n","| train/                  |             |\n","|    approx_kl            | 0.018440956 |\n","|    clip_fraction        | 0.143       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.445      |\n","|    explained_variance   | 0.305       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 27.5        |\n","|    n_updates            | 250         |\n","|    policy_gradient_loss | -0.0016     |\n","|    value_loss           | 68.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 46.6        |\n","|    ep_rew_mean          | 46.6        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 27          |\n","|    time_elapsed         | 987         |\n","|    total_timesteps      | 221184      |\n","| train/                  |             |\n","|    approx_kl            | 0.019191692 |\n","|    clip_fraction        | 0.154       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.441      |\n","|    explained_variance   | 0.283       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 33.6        |\n","|    n_updates            | 260         |\n","|    policy_gradient_loss | -0.00246    |\n","|    value_loss           | 69.2        |\n","-----------------------------------------\n","----------------------------------------\n","| rollout/                |            |\n","|    ep_len_mean          | 51.1       |\n","|    ep_rew_mean          | 51.1       |\n","| time/                   |            |\n","|    fps                  | 224        |\n","|    iterations           | 28         |\n","|    time_elapsed         | 1023       |\n","|    total_timesteps      | 229376     |\n","| train/                  |            |\n","|    approx_kl            | 0.02057437 |\n","|    clip_fraction        | 0.141      |\n","|    clip_range           | 0.2        |\n","|    entropy_loss         | -0.444     |\n","|    explained_variance   | 0.304      |\n","|    learning_rate        | 0.0003     |\n","|    loss                 | 43.7       |\n","|    n_updates            | 270        |\n","|    policy_gradient_loss | -0.00076   |\n","|    value_loss           | 70.1       |\n","----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 46.4        |\n","|    ep_rew_mean          | 46.4        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 29          |\n","|    time_elapsed         | 1059        |\n","|    total_timesteps      | 237568      |\n","| train/                  |             |\n","|    approx_kl            | 0.017194845 |\n","|    clip_fraction        | 0.167       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.45       |\n","|    explained_variance   | 0.315       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 34.6        |\n","|    n_updates            | 280         |\n","|    policy_gradient_loss | 0.00166     |\n","|    value_loss           | 69          |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 45.3        |\n","|    ep_rew_mean          | 45.3        |\n","| time/                   |             |\n","|    fps                  | 224         |\n","|    iterations           | 30          |\n","|    time_elapsed         | 1096        |\n","|    total_timesteps      | 245760      |\n","| train/                  |             |\n","|    approx_kl            | 0.016449548 |\n","|    clip_fraction        | 0.143       |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.445      |\n","|    explained_variance   | 0.331       |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 29.4        |\n","|    n_updates            | 290         |\n","|    policy_gradient_loss | -0.000823   |\n","|    value_loss           | 74.8        |\n","-----------------------------------------\n","-----------------------------------------\n","| rollout/                |             |\n","|    ep_len_mean          | 49.6        |\n","|    ep_rew_mean          | 49.6        |\n","| time/                   |             |\n","|    fps                  | 223         |\n","|    iterations           | 31          |\n","|    time_elapsed         | 1134        |\n","|    total_timesteps      | 253952      |\n","| train/                  |             |\n","|    approx_kl            | 0.017563518 |\n","|    clip_fraction        | 0.15        |\n","|    clip_range           | 0.2         |\n","|    entropy_loss         | -0.437      |\n","|    explained_variance   | 0.29        |\n","|    learning_rate        | 0.0003      |\n","|    loss                 | 37          |\n","|    n_updates            | 300         |\n","|    policy_gradient_loss | -0.000275   |\n","|    value_loss           | 72.5        |\n","-----------------------------------------\n","\n","‚úÖ Training complete and model saved to /project/models/ppo_visual_cartpole.zip\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y1NJWr4TzIoE"},"execution_count":null,"outputs":[]}]}